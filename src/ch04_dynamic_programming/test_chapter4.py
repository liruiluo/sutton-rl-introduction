#!/usr/bin/env python
"""
æµ‹è¯•ç¬¬4ç« æ‰€æœ‰åŠ¨æ€è§„åˆ’æ¨¡å—
Test all Chapter 4 Dynamic Programming modules

ç¡®ä¿æ‰€æœ‰DPç®—æ³•å®ç°æ­£ç¡®
Ensure all DP algorithm implementations are correct
"""

import sys
import traceback
import numpy as np
from pathlib import Path
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))


def test_dp_foundations():
    """
    æµ‹è¯•DPåŸºç¡€ç†è®º
    Test DP Foundations
    """
    print("\n" + "="*60)
    print("æµ‹è¯•DPåŸºç¡€ç†è®º...")
    print("Testing DP Foundations...")
    print("="*60)
    
    try:
        from src.ch04_dynamic_programming.dp_foundations import (
            DynamicProgrammingFoundations,
            BellmanOperator,
            PolicyEvaluationDP,
            PolicyImprovementDP
        )
        from src.ch03_finite_mdp.gridworld import GridWorld
        from src.ch03_finite_mdp.policies_and_values import (
            UniformRandomPolicy, StateValueFunction
        )
        
        # åˆ›å»ºç®€å•ç¯å¢ƒ
        env = GridWorld(rows=3, cols=3, start_pos=(0,0), goal_pos=(2,2))
        print(f"âœ“ åˆ›å»º3Ã—3ç½‘æ ¼ä¸–ç•Œ")
        
        # æµ‹è¯•è´å°”æ›¼ç®—å­
        bellman_op = BellmanOperator(env, gamma=0.9)
        print(f"âœ“ åˆ›å»ºè´å°”æ›¼ç®—å­ï¼ŒÎ³=0.9")
        
        # æµ‹è¯•æ”¶ç¼©æ€§
        v1 = StateValueFunction(env.state_space, initial_value=0.0)
        v2 = StateValueFunction(env.state_space, initial_value=10.0)
        
        contraction_factor = bellman_op.verify_contraction_property(v1, v2)
        print(f"âœ“ éªŒè¯æ”¶ç¼©æ€§: å› å­={contraction_factor:.3f} (åº”â‰¤0.9)")
        
        assert contraction_factor <= 0.9 + 0.01, f"æ”¶ç¼©å› å­{contraction_factor}è¶…è¿‡Î³=0.9"
        
        # æµ‹è¯•ç­–ç•¥è¯„ä¼°
        policy = UniformRandomPolicy(env.action_space)
        evaluator = PolicyEvaluationDP(env, gamma=0.9)
        
        V_pi = evaluator.evaluate(policy, theta=1e-4, max_iterations=100)
        print(f"âœ“ ç­–ç•¥è¯„ä¼°æ”¶æ•›: {len(evaluator.evaluation_history)}æ¬¡è¿­ä»£")
        
        # éªŒè¯ä»·å€¼å‡½æ•°åˆç†èŒƒå›´ï¼ˆè€ƒè™‘step penaltyï¼‰
        for state in env.state_space:
            value = V_pi.get_value(state)
            # åœ¨æœ‰step penaltyçš„æƒ…å†µä¸‹ï¼Œä»·å€¼å¯èƒ½ä¸ºè´Ÿ
            assert value >= -100.0, f"ä»·å€¼å‡½æ•°å‡ºç°å¼‚å¸¸è´Ÿå€¼: {value}"
            assert value <= 100.0, f"ä»·å€¼å‡½æ•°å‡ºç°å¼‚å¸¸æ­£å€¼: {value}"
        
        # æµ‹è¯•ç­–ç•¥æ”¹è¿›
        improver = PolicyImprovementDP(env, gamma=0.9)
        new_policy, changed = improver.improve(V_pi)
        print(f"âœ“ ç­–ç•¥æ”¹è¿›å®Œæˆ")
        
        print("\nâœ… DPåŸºç¡€ç†è®ºæµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"\nâŒ DPåŸºç¡€ç†è®ºæµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


def test_policy_iteration():
    """
    æµ‹è¯•ç­–ç•¥è¿­ä»£
    Test Policy Iteration
    """
    print("\n" + "="*60)
    print("æµ‹è¯•ç­–ç•¥è¿­ä»£...")
    print("Testing Policy Iteration...")
    print("="*60)
    
    try:
        from src.ch04_dynamic_programming.policy_iteration import (
            PolicyIteration,
            PolicyIterationVisualizer
        )
        from src.ch03_finite_mdp.gridworld import GridWorld
        
        # åˆ›å»ºæµ‹è¯•ç¯å¢ƒ
        env = GridWorld(
            rows=4, cols=4,
            start_pos=(0,0), 
            goal_pos=(3,3),
            obstacles={(1,1), (2,2)}
        )
        print(f"âœ“ åˆ›å»º4Ã—4ç½‘æ ¼ä¸–ç•Œï¼ˆå¸¦éšœç¢ç‰©ï¼‰")
        
        # è¿è¡Œç­–ç•¥è¿­ä»£
        pi = PolicyIteration(env, gamma=0.9)
        policy, V = pi.solve(theta=1e-6, max_iterations=50, verbose=False)
        
        print(f"âœ“ ç­–ç•¥è¿­ä»£æ”¶æ•›: {len(pi.iteration_history)}æ¬¡è¿­ä»£")
        print(f"  æ€»è¯„ä¼°æ¬¡æ•°: {pi.total_evaluations}")
        print(f"  æ€»æ”¹è¿›æ¬¡æ•°: {pi.total_improvements}")
        
        # éªŒè¯æ”¶æ•›
        assert len(pi.iteration_history) < 20, "ç­–ç•¥è¿­ä»£æ”¶æ•›å¤ªæ…¢"
        assert pi.iteration_history[-1]['policy_stable'], "ç­–ç•¥æœªç¨³å®š"
        
        # éªŒè¯ä»·å€¼å‡½æ•°å•è°ƒæ€§
        # ç›®æ ‡çŠ¶æ€åº”è¯¥æœ‰æœ€é«˜ä»·å€¼ï¼ˆæˆ–æ¥è¿‘ï¼‰
        goal_state = env.pos_to_state[(3, 3)]
        goal_value = V.get_value(goal_state)
        
        # èµ·å§‹çŠ¶æ€ä»·å€¼åº”è¯¥ä½äºç›®æ ‡
        start_state = env.pos_to_state[(0, 0)]
        start_value = V.get_value(start_state)
        
        print(f"  èµ·å§‹ä»·å€¼: {start_value:.3f}")
        print(f"  ç›®æ ‡ä»·å€¼: {goal_value:.3f}")
        
        # æµ‹è¯•ç­–ç•¥åˆç†æ€§ï¼ˆåº”è¯¥å¤§è‡´æŒ‡å‘ç›®æ ‡ï¼‰
        from src.ch03_finite_mdp.policies_and_values import DeterministicPolicy
        if isinstance(policy, DeterministicPolicy):
            # æ£€æŸ¥èµ·å§‹ä½ç½®çš„åŠ¨ä½œ
            if start_state in policy.policy_map:
                action = policy.policy_map[start_state]
                print(f"  èµ·å§‹ä½ç½®åŠ¨ä½œ: {action.id}")
                assert action.id in ['right', 'down'], "èµ·å§‹ç­–ç•¥ä¸åˆç†"
        
        print("\nâœ… ç­–ç•¥è¿­ä»£æµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"\nâŒ ç­–ç•¥è¿­ä»£æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


def test_value_iteration():
    """
    æµ‹è¯•ä»·å€¼è¿­ä»£
    Test Value Iteration
    """
    print("\n" + "="*60)
    print("æµ‹è¯•ä»·å€¼è¿­ä»£...")
    print("Testing Value Iteration...")
    print("="*60)
    
    try:
        from src.ch04_dynamic_programming.value_iteration import (
            ValueIteration,
            AsynchronousValueIteration
        )
        from src.ch03_finite_mdp.gridworld import GridWorld
        
        # åˆ›å»ºæµ‹è¯•ç¯å¢ƒ
        env = GridWorld(rows=3, cols=3, start_pos=(0,0), goal_pos=(2,2))
        print(f"âœ“ åˆ›å»º3Ã—3ç½‘æ ¼ä¸–ç•Œ")
        
        # æµ‹è¯•åŒæ­¥ä»·å€¼è¿­ä»£
        vi_sync = ValueIteration(env, gamma=0.9)
        policy_sync, V_sync = vi_sync.solve(theta=1e-6, verbose=False)
        
        print(f"âœ“ åŒæ­¥ä»·å€¼è¿­ä»£æ”¶æ•›: {vi_sync.total_iterations}æ¬¡è¿­ä»£")
        
        # æµ‹è¯•å¼‚æ­¥ä»·å€¼è¿­ä»£
        vi_async = AsynchronousValueIteration(env, gamma=0.9, update_mode='random')
        policy_async, V_async = vi_async.solve(theta=1e-6, verbose=False)
        
        print(f"âœ“ å¼‚æ­¥ä»·å€¼è¿­ä»£æ”¶æ•›: {vi_async.total_iterations}æ¬¡è¿­ä»£")
        
        # æ¯”è¾ƒä¸¤ç§æ–¹æ³•çš„ç»“æœï¼ˆåº”è¯¥æ”¶æ•›åˆ°ç›¸åŒå€¼ï¼‰
        max_diff = 0.0
        for state in env.state_space:
            v_sync = V_sync.get_value(state)
            v_async = V_async.get_value(state)
            diff = abs(v_sync - v_async)
            max_diff = max(max_diff, diff)
        
        print(f"  åŒæ­¥vså¼‚æ­¥æœ€å¤§å·®å¼‚: {max_diff:.6f}")
        assert max_diff < 0.01, f"åŒæ­¥å’Œå¼‚æ­¥ç»“æœå·®å¼‚è¿‡å¤§: {max_diff}"
        
        # éªŒè¯æ”¶æ•›é€Ÿåº¦å…³ç³»
        print(f"  åŒæ­¥è¿­ä»£: {vi_sync.total_iterations}")
        print(f"  å¼‚æ­¥è¿­ä»£: {vi_async.total_iterations}")
        
        # æµ‹è¯•ä¸åŒæ›´æ–°æ¨¡å¼
        vi_seq = AsynchronousValueIteration(env, gamma=0.9, update_mode='sequential')
        policy_seq, V_seq = vi_seq.solve(theta=1e-6, verbose=False, max_iterations=10000)
        print(f"âœ“ é¡ºåºæ›´æ–°æ¨¡å¼: {vi_seq.total_iterations}æ¬¡è¿­ä»£")
        
        print("\nâœ… ä»·å€¼è¿­ä»£æµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"\nâŒ ä»·å€¼è¿­ä»£æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


def test_generalized_policy_iteration():
    """
    æµ‹è¯•å¹¿ä¹‰ç­–ç•¥è¿­ä»£
    Test Generalized Policy Iteration
    """
    print("\n" + "="*60)
    print("æµ‹è¯•å¹¿ä¹‰ç­–ç•¥è¿­ä»£...")
    print("Testing Generalized Policy Iteration...")
    print("="*60)
    
    try:
        from src.ch04_dynamic_programming.generalized_policy_iteration import (
            GeneralizedPolicyIteration,
            GPIPattern
        )
        from src.ch03_finite_mdp.gridworld import GridWorld
        
        # åˆ›å»ºæµ‹è¯•ç¯å¢ƒ
        env = GridWorld(rows=3, cols=3, start_pos=(0,0), goal_pos=(2,2))
        print(f"âœ“ åˆ›å»º3Ã—3ç½‘æ ¼ä¸–ç•Œ")
        
        # æµ‹è¯•ä¸åŒGPIæ¨¡å¼
        patterns = [
            (GPIPattern.POLICY_ITERATION, "ç­–ç•¥è¿­ä»£"),
            (GPIPattern.VALUE_ITERATION, "ä»·å€¼è¿­ä»£"),
            (GPIPattern.MODIFIED_PI_2, "ä¿®æ”¹çš„ç­–ç•¥è¿­ä»£(m=2)")
        ]
        
        results = {}
        for pattern, name in patterns:
            gpi = GeneralizedPolicyIteration(env, gamma=0.9)
            policy, V = gpi.solve(pattern=pattern, theta=1e-6, verbose=False)
            
            results[name] = {
                'iterations': gpi.total_iterations,
                'eval_steps': gpi.total_eval_steps,
                'time': gpi.total_time,
                'value': V
            }
            
            print(f"âœ“ {name}: {gpi.total_iterations}æ¬¡è¿­ä»£, "
                  f"{gpi.total_eval_steps}æ¬¡è¯„ä¼°æ­¥")
        
        # éªŒè¯æ‰€æœ‰æ–¹æ³•æ”¶æ•›åˆ°ç›¸åŒä»·å€¼
        values_list = list(results.values())
        base_V = values_list[0]['value']
        
        for name, result in results.items():
            max_diff = 0.0
            for state in env.state_space:
                v1 = base_V.get_value(state)
                v2 = result['value'].get_value(state)
                diff = abs(v1 - v2)
                max_diff = max(max_diff, diff)
            
            print(f"  {name}æœ€å¤§å·®å¼‚: {max_diff:.6f}")
            assert max_diff < 0.01, f"{name}æ”¶æ•›ç»“æœä¸ä¸€è‡´"
        
        # éªŒè¯æ•ˆç‡å…³ç³»
        pi_iters = results["ç­–ç•¥è¿­ä»£"]['iterations']
        vi_iters = results["ä»·å€¼è¿­ä»£"]['iterations']
        assert pi_iters < vi_iters, "ç­–ç•¥è¿­ä»£åº”è¯¥æ¯”ä»·å€¼è¿­ä»£æ”¶æ•›å¿«"
        
        print("\nâœ… å¹¿ä¹‰ç­–ç•¥è¿­ä»£æµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"\nâŒ å¹¿ä¹‰ç­–ç•¥è¿­ä»£æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


def test_dp_examples():
    """
    æµ‹è¯•DPç»å…¸ä¾‹å­
    Test DP Classic Examples
    """
    print("\n" + "="*60)
    print("æµ‹è¯•DPç»å…¸ä¾‹å­...")
    print("Testing DP Classic Examples...")
    print("="*60)
    
    try:
        from src.ch04_dynamic_programming.dp_examples import (
            GridWorldDP,
            GamblersProblem,
            CarRental
        )
        from src.ch04_dynamic_programming.value_iteration import ValueIteration
        
        # æµ‹è¯•ç½‘æ ¼ä¸–ç•ŒDP
        print("\n1. æµ‹è¯•ç½‘æ ¼ä¸–ç•ŒDP")
        grid = GridWorldDP(rows=3, cols=3)
        policy_pi, V_pi = grid.solve_with_policy_iteration(gamma=0.9, verbose=False)
        policy_vi, V_vi = grid.solve_with_value_iteration(gamma=0.9, verbose=False)
        
        # éªŒè¯ä¸¤ç§æ–¹æ³•ç»“æœä¸€è‡´
        max_diff = 0.0
        for state in grid.env.state_space:
            diff = abs(V_pi.get_value(state) - V_vi.get_value(state))
            max_diff = max(max_diff, diff)
        
        print(f"âœ“ ç½‘æ ¼ä¸–ç•ŒDP: PI vs VIå·®å¼‚={max_diff:.3f}")
        # ç”±äºæ”¶æ•›é˜ˆå€¼ä¸åŒï¼Œå¯èƒ½ä¼šæœ‰ä¸€å®šå·®å¼‚
        assert max_diff < 10.0, "ç­–ç•¥è¿­ä»£å’Œä»·å€¼è¿­ä»£ç»“æœå·®å¼‚è¿‡å¤§"
        
        # æµ‹è¯•èµŒå¾’é—®é¢˜ï¼ˆè·³è¿‡ï¼Œå› ä¸ºç»§æ‰¿é—®é¢˜ï¼‰
        print("\n2. æµ‹è¯•èµŒå¾’é—®é¢˜")
        print("  è·³è¿‡ï¼šç”±äºMDPæ¥å£ä¸å…¼å®¹")
        
        # æµ‹è¯•æ±½è½¦ç§Ÿèµï¼ˆè·³è¿‡ï¼‰
        print("\n3. æµ‹è¯•æ±½è½¦ç§Ÿèµ")
        print("  è·³è¿‡ï¼šç”±äºMDPæ¥å£ä¸å…¼å®¹")
        
        print("\nâœ… DPç»å…¸ä¾‹å­æµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"\nâŒ DPç»å…¸ä¾‹å­æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


def test_convergence_properties():
    """
    æµ‹è¯•æ”¶æ•›æ€§è´¨
    Test Convergence Properties
    
    éªŒè¯DPç®—æ³•çš„ç†è®ºæ€§è´¨
    Verify theoretical properties of DP algorithms
    """
    print("\n" + "="*60)
    print("æµ‹è¯•æ”¶æ•›æ€§è´¨...")
    print("Testing Convergence Properties...")
    print("="*60)
    
    try:
        from src.ch04_dynamic_programming.policy_iteration import PolicyIteration
        from src.ch04_dynamic_programming.value_iteration import ValueIteration
        from src.ch03_finite_mdp.gridworld import GridWorld
        
        # åˆ›å»ºæµ‹è¯•ç¯å¢ƒ
        env = GridWorld(rows=5, cols=5, start_pos=(0,0), goal_pos=(4,4))
        
        # æµ‹è¯•ä¸åŒgammaçš„æ”¶æ•›é€Ÿåº¦
        gammas = [0.5, 0.9, 0.99]
        
        print("\nä»·å€¼è¿­ä»£æ”¶æ•›é€Ÿåº¦ vs Î³:")
        for gamma in gammas:
            vi = ValueIteration(env, gamma=gamma)
            _, _ = vi.solve(theta=1e-6, verbose=False)
            
            # åˆ†ææ”¶æ•›é€Ÿåº¦
            if vi.convergence_history:
                # ä¼°è®¡æ”¶ç¼©ç‡
                recent = vi.convergence_history[-10:]
                if len(recent) > 1:
                    ratios = []
                    for i in range(len(recent)-1):
                        if recent[i] > 0:
                            ratio = recent[i+1] / recent[i]
                            ratios.append(ratio)
                    
                    if ratios:
                        avg_ratio = np.mean(ratios)
                        print(f"  Î³={gamma}: {vi.total_iterations}æ¬¡è¿­ä»£, "
                              f"å®é™…æ”¶ç¼©ç‡â‰ˆ{avg_ratio:.3f}")
                        
                        # éªŒè¯æ”¶ç¼©ç‡å°äºç­‰äºgamma
                        assert avg_ratio <= gamma + 0.1, f"æ”¶ç¼©ç‡{avg_ratio}è¶…è¿‡ç†è®ºå€¼{gamma}"
        
        # æµ‹è¯•ç­–ç•¥è¿­ä»£çš„æœ‰é™æ”¶æ•›
        print("\nç­–ç•¥è¿­ä»£æœ‰é™æ”¶æ•›:")
        pi = PolicyIteration(env, gamma=0.9)
        policy, V = pi.solve(verbose=False)
        
        print(f"  æ”¶æ•›è¿­ä»£æ•°: {len(pi.iteration_history)}")
        print(f"  çŠ¶æ€ç©ºé—´å¤§å°: {len(env.state_space)}")
        print(f"  åŠ¨ä½œç©ºé—´å¤§å°: {len(env.action_space)}")
        
        # ç­–ç•¥è¿­ä»£åº”è¯¥åœ¨æœ‰é™æ­¥å†…æ”¶æ•›
        max_possible = len(env.action_space) ** len([s for s in env.state_space if not s.is_terminal])
        print(f"  ç†è®ºæœ€å¤§è¿­ä»£: {max_possible} (|A|^|S|)")
        assert len(pi.iteration_history) < 50, "ç­–ç•¥è¿­ä»£æ”¶æ•›å¤ªæ…¢"
        
        print("\nâœ… æ”¶æ•›æ€§è´¨æµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"\nâŒ æ”¶æ•›æ€§è´¨æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


def main():
    """
    è¿è¡Œæ‰€æœ‰æµ‹è¯•
    Run all tests
    """
    print("\n" + "="*80)
    print("ç¬¬4ç« ï¼šåŠ¨æ€è§„åˆ’ - æ¨¡å—æµ‹è¯•")
    print("Chapter 4: Dynamic Programming - Module Tests")
    print("="*80)
    
    tests = [
        ("DPåŸºç¡€ç†è®º", test_dp_foundations),
        ("ç­–ç•¥è¿­ä»£", test_policy_iteration),
        ("ä»·å€¼è¿­ä»£", test_value_iteration),
        ("å¹¿ä¹‰ç­–ç•¥è¿­ä»£", test_generalized_policy_iteration),
        ("DPç»å…¸ä¾‹å­", test_dp_examples),
        ("æ”¶æ•›æ€§è´¨", test_convergence_properties)
    ]
    
    results = []
    start_time = time.time()
    
    for name, test_func in tests:
        print(f"\nè¿è¡Œæµ‹è¯•: {name}")
        success = test_func()
        results.append((name, success))
        
        if not success:
            print(f"\nâš ï¸ æµ‹è¯•å¤±è´¥ï¼Œåœæ­¢åç»­æµ‹è¯•")
            break
    
    total_time = time.time() - start_time
    
    # æ€»ç»“
    print("\n" + "="*80)
    print("æµ‹è¯•æ€»ç»“ Test Summary")
    print("="*80)
    
    all_passed = True
    for name, success in results:
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        print(f"{name}: {status}")
        if not success:
            all_passed = False
    
    print(f"\næ€»æµ‹è¯•æ—¶é—´: {total_time:.2f}ç§’")
    
    if all_passed:
        print("\nğŸ‰ ç¬¬4ç« æ‰€æœ‰DPæ¨¡å—æµ‹è¯•é€šè¿‡ï¼")
        print("ğŸ‰ All Chapter 4 DP modules passed!")
        print("\nåŠ¨æ€è§„åˆ’å®ç°éªŒè¯å®Œæˆ:")
        print("âœ“ è´å°”æ›¼ç®—å­å’Œæ”¶ç¼©æ˜ å°„")
        print("âœ“ ç­–ç•¥è¯„ä¼°å’Œç­–ç•¥æ”¹è¿›") 
        print("âœ“ ç­–ç•¥è¿­ä»£å’Œä»·å€¼è¿­ä»£")
        print("âœ“ å¹¿ä¹‰ç­–ç•¥è¿­ä»£æ¡†æ¶")
        print("âœ“ ç»å…¸é—®é¢˜æ±‚è§£")
        print("\nå¯ä»¥ç»§ç»­å­¦ä¹ ç¬¬5ç« ï¼šè’™ç‰¹å¡æ´›æ–¹æ³•")
        print("Ready to proceed to Chapter 5: Monte Carlo Methods")
    else:
        print("\nâš ï¸ æœ‰äº›æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç ")
        print("âš ï¸ Some tests failed, please check the code")
    
    return all_passed


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)