#!/usr/bin/env python
"""
æµ‹è¯•ç¬¬12ç« æ‰€æœ‰èµ„æ ¼è¿¹æ¨¡å—
Test all Chapter 12 Eligibility Traces modules

ç¡®ä¿æ‰€æœ‰èµ„æ ¼è¿¹ç®—æ³•å®ç°æ­£ç¡®
Ensure all eligibility trace algorithm implementations are correct
"""

import sys
import traceback
import numpy as np
from pathlib import Path
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))


def test_lambda_return():
    """
    æµ‹è¯•Î»-returnæ–¹æ³•
    Test Î»-return methods
    """
    print("\n" + "="*60)
    print("æµ‹è¯•Î»-return...")
    print("Testing Î»-return...")
    print("="*60)
    
    try:
        from src.ch12_eligibility_traces.lambda_return import (
            Episode, LambdaReturn, OfflineLambdaReturn,
            SemiGradientLambdaReturn, TTD
        )
        
        # æµ‹è¯•Episode
        print("\næµ‹è¯•Episodeæ•°æ®ç»“æ„...")
        episode = Episode(
            states=[0, 1, 2, 3],
            actions=[0, 1, 0, 1],
            rewards=[1.0, -1.0, 2.0, -0.5]
        )
        
        assert episode.length == 4
        g = episode.compute_return(0, gamma=0.9)
        assert isinstance(g, float)
        print(f"  âœ“ Episodeæµ‹è¯•é€šè¿‡ï¼Œå›æŠ¥={g:.3f}")
        
        # æµ‹è¯•LambdaReturnè®¡ç®—å™¨
        print("\næµ‹è¯•Î»-returnè®¡ç®—å™¨...")
        lambda_calc = LambdaReturn(lambda_=0.8, gamma=0.9)
        g_lambda = lambda_calc.compute_lambda_return(episode, t=0)
        assert isinstance(g_lambda, float)
        print(f"  âœ“ Î»-returnè®¡ç®—æµ‹è¯•é€šè¿‡ï¼ŒG^Î»={g_lambda:.3f}")
        
        # æµ‹è¯•ç¦»çº¿Î»-return
        print("\næµ‹è¯•ç¦»çº¿Î»-return...")
        n_features = 8
        
        def simple_features(state):
            features = np.zeros(n_features)
            if isinstance(state, int):
                features[state % n_features] = 1.0
            return features
        
        offline_lambda = OfflineLambdaReturn(
            n_features=n_features,
            feature_extractor=simple_features,
            lambda_=0.9,
            alpha=0.1,
            gamma=0.9
        )
        
        offline_lambda.learn_episode(episode)
        assert offline_lambda.episode_count == 1
        assert offline_lambda.total_updates > 0
        print(f"  âœ“ ç¦»çº¿Î»-returnæµ‹è¯•é€šè¿‡ï¼Œæ›´æ–°{offline_lambda.total_updates}æ¬¡")
        
        # æµ‹è¯•åŠæ¢¯åº¦Î»-return
        print("\næµ‹è¯•åŠæ¢¯åº¦Î»-return...")
        sg_lambda = SemiGradientLambdaReturn(
            n_features=n_features,
            feature_extractor=simple_features,
            lambda_=0.8,
            alpha=0.05,
            gamma=0.9
        )
        
        sg_lambda.start_episode()
        for i in range(3):
            sg_lambda.step(i, -1.0, i+1, i == 2)
        
        assert sg_lambda.update_count > 0
        print(f"  âœ“ åŠæ¢¯åº¦Î»-returnæµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•TTD
        print("\næµ‹è¯•TTD...")
        ttd = TTD(
            n_features=n_features,
            feature_extractor=simple_features,
            lambda_=0.9,
            alpha=0.05,
            gamma=0.9,
            horizon=3
        )
        
        for i in range(5):
            ttd.step(i % 3, -1.0, (i+1) % 3, False)
        
        assert ttd.step_count == 5
        print(f"  âœ“ TTDæµ‹è¯•é€šè¿‡ï¼Œæ­¥æ•°={ttd.step_count}")
        
        print("\nâœ… Î»-returnæµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"\nâŒ Î»-returnæµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


def test_td_lambda():
    """
    æµ‹è¯•TD(Î»)ç®—æ³•
    Test TD(Î») algorithms
    """
    print("\n" + "="*60)
    print("æµ‹è¯•TD(Î»)ç®—æ³•...")
    print("Testing TD(Î») Algorithms...")
    print("="*60)
    
    try:
        from src.ch12_eligibility_traces.td_lambda import (
            TDLambda, TrueOnlineTDLambda, TruncatedTDLambda, VariableLambdaTD
        )
        
        n_features = 10
        
        def tile_features(state):
            features = np.zeros(n_features)
            if isinstance(state, int):
                features[state % n_features] = 1.0
                features[(state * 2) % n_features] = 0.5
            return features
        
        # æµ‹è¯•åŸºç¡€TD(Î»)
        print("\næµ‹è¯•åŸºç¡€TD(Î»)...")
        td_lambda = TDLambda(
            n_features=n_features,
            feature_extractor=tile_features,
            lambda_=0.9,
            alpha=0.05,
            gamma=0.95,
            trace_type='accumulating'
        )
        
        for i in range(10):
            td_error = td_lambda.update(i % 5, -1.0, (i+1) % 5, i == 9)
            assert isinstance(td_error, float)
        
        stats = td_lambda.get_statistics()
        assert 'mean_td_error' in stats
        assert td_lambda.update_count == 10
        print(f"  âœ“ åŸºç¡€TD(Î»)æµ‹è¯•é€šè¿‡ï¼Œè¿¹å¤§å°={stats['mean_trace_magnitude']:.3f}")
        
        # æµ‹è¯•æ›¿æ¢è¿¹
        print("\næµ‹è¯•æ›¿æ¢è¿¹TD(Î»)...")
        td_lambda_rep = TDLambda(
            n_features=n_features,
            feature_extractor=tile_features,
            lambda_=0.9,
            alpha=0.05,
            gamma=0.95,
            trace_type='replacing'
        )
        
        for i in range(10):
            td_lambda_rep.update(i % 5, -1.0, (i+1) % 5, i == 9)
        
        assert td_lambda_rep.update_count == 10
        print(f"  âœ“ æ›¿æ¢è¿¹TD(Î»)æµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•çœŸæ­£çš„åœ¨çº¿TD(Î»)
        print("\næµ‹è¯•çœŸæ­£çš„åœ¨çº¿TD(Î»)...")
        true_online_td = TrueOnlineTDLambda(
            n_features=n_features,
            feature_extractor=tile_features,
            lambda_=0.9,
            alpha=0.05,
            gamma=0.95
        )
        
        for i in range(10):
            td_error = true_online_td.update(i % 5, -1.0, (i+1) % 5, i == 9)
            assert isinstance(td_error, float)
        
        assert true_online_td.update_count == 10
        print(f"  âœ“ çœŸæ­£çš„åœ¨çº¿TD(Î»)æµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•æˆªæ–­TD(Î»)
        print("\næµ‹è¯•æˆªæ–­TD(Î»)...")
        truncated_td = TruncatedTDLambda(
            n_features=n_features,
            feature_extractor=tile_features,
            lambda_=0.9,
            alpha=0.05,
            gamma=0.95,
            trace_threshold=0.01
        )
        
        for i in range(20):
            truncated_td.update(i % 5, -1.0, (i+1) % 5, i == 19)
        
        stats = truncated_td.get_statistics()
        assert 'mean_active_traces' in stats
        print(f"  âœ“ æˆªæ–­TD(Î»)æµ‹è¯•é€šè¿‡ï¼Œæ´»è·ƒè¿¹={stats['mean_active_traces']:.1f}")
        
        # æµ‹è¯•å˜Î»TD
        print("\næµ‹è¯•å˜Î»TD...")
        def lambda_func(state):
            if isinstance(state, int):
                return 0.9 if state % 5 == 0 else 0.5
            return 0.7
        
        variable_td = VariableLambdaTD(
            n_features=n_features,
            feature_extractor=tile_features,
            lambda_function=lambda_func,
            alpha=0.05,
            gamma=0.95
        )
        
        for i in range(10):
            variable_td.update(i % 5, -1.0, (i+1) % 5, i == 9)
        
        assert variable_td.update_count == 10
        assert len(variable_td.lambda_history) == 10
        print(f"  âœ“ å˜Î»TDæµ‹è¯•é€šè¿‡")
        
        print("\nâœ… TD(Î»)ç®—æ³•æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"\nâŒ TD(Î»)ç®—æ³•æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


def test_control_traces():
    """
    æµ‹è¯•æ§åˆ¶ç®—æ³•çš„èµ„æ ¼è¿¹
    Test control algorithms with eligibility traces
    """
    print("\n" + "="*60)
    print("æµ‹è¯•æ§åˆ¶ç®—æ³•èµ„æ ¼è¿¹...")
    print("Testing Control with Eligibility Traces...")
    print("="*60)
    
    try:
        from src.ch12_eligibility_traces.control_traces import (
            SarsaLambda, WatkinsQLambda, PengQLambda, TrueOnlineSarsaLambda
        )
        
        n_features = 10
        n_actions = 3
        
        def sa_features(state, action):
            features = np.zeros(n_features)
            if isinstance(state, int):
                base_idx = (state * n_actions + action) % n_features
                features[base_idx] = 1.0
            return features
        
        # æµ‹è¯•Sarsa(Î»)
        print("\næµ‹è¯•Sarsa(Î»)...")
        sarsa_lambda = SarsaLambda(
            n_features=n_features,
            n_actions=n_actions,
            feature_extractor=sa_features,
            lambda_=0.9,
            alpha=0.1,
            gamma=0.95,
            epsilon=0.1,
            trace_type='accumulating'
        )
        
        # æ¨¡æ‹Ÿæ›´æ–°
        for i in range(10):
            state = i % 5
            action = sarsa_lambda.select_action(state)
            next_state = (i + 1) % 5
            next_action = sarsa_lambda.select_action(next_state)
            
            td_error = sarsa_lambda.update(
                state, action, -1.0, next_state, next_action, i == 9
            )
            assert isinstance(td_error, float)
        
        assert sarsa_lambda.update_count == 10
        print(f"  âœ“ Sarsa(Î»)æµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•Watkins's Q(Î»)
        print("\næµ‹è¯•Watkins's Q(Î»)...")
        watkins_q = WatkinsQLambda(
            n_features=n_features,
            n_actions=n_actions,
            feature_extractor=sa_features,
            lambda_=0.9,
            alpha=0.1,
            gamma=0.95,
            epsilon=0.1
        )
        
        for i in range(10):
            state = i % 5
            action, was_greedy = watkins_q.select_action(state)
            next_state = (i + 1) % 5
            
            td_error = watkins_q.update(
                state, action, -1.0, next_state, i == 9, was_greedy
            )
            assert isinstance(td_error, float)
        
        assert watkins_q.update_count == 10
        print(f"  âœ“ Watkins's Q(Î»)æµ‹è¯•é€šè¿‡ï¼Œè¿¹æˆªæ–­{watkins_q.trace_cuts}æ¬¡")
        
        # æµ‹è¯•Peng's Q(Î»)
        print("\næµ‹è¯•Peng's Q(Î»)...")
        peng_q = PengQLambda(
            n_features=n_features,
            n_actions=n_actions,
            feature_extractor=sa_features,
            lambda_=0.9,
            alpha=0.1,
            gamma=0.95,
            epsilon=0.1
        )
        
        for i in range(10):
            state = i % 5
            action = peng_q.select_action(state)
            next_state = (i + 1) % 5
            
            td_error = peng_q.update(state, action, -1.0, next_state, i == 9)
            assert isinstance(td_error, float)
        
        assert peng_q.update_count == 10
        print(f"  âœ“ Peng's Q(Î»)æµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•çœŸæ­£çš„åœ¨çº¿Sarsa(Î»)
        print("\næµ‹è¯•çœŸæ­£çš„åœ¨çº¿Sarsa(Î»)...")
        true_online_sarsa = TrueOnlineSarsaLambda(
            n_features=n_features,
            n_actions=n_actions,
            feature_extractor=sa_features,
            lambda_=0.9,
            alpha=0.1,
            gamma=0.95,
            epsilon=0.1
        )
        
        for i in range(10):
            state = i % 5
            action = true_online_sarsa.select_action(state)
            next_state = (i + 1) % 5
            next_action = true_online_sarsa.select_action(next_state)
            
            td_error = true_online_sarsa.update(
                state, action, -1.0, next_state, next_action, i == 9
            )
            assert isinstance(td_error, float)
        
        assert true_online_sarsa.update_count == 10
        print(f"  âœ“ çœŸæ­£çš„åœ¨çº¿Sarsa(Î»)æµ‹è¯•é€šè¿‡")
        
        print("\nâœ… æ§åˆ¶ç®—æ³•èµ„æ ¼è¿¹æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"\nâŒ æ§åˆ¶ç®—æ³•èµ„æ ¼è¿¹æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


def test_integration():
    """
    æµ‹è¯•é›†æˆåœºæ™¯
    Test integration scenarios
    """
    print("\n" + "="*60)
    print("æµ‹è¯•é›†æˆåœºæ™¯...")
    print("Testing Integration Scenarios...")
    print("="*60)
    
    try:
        from src.ch12_eligibility_traces.lambda_return import Episode, LambdaReturn
        from src.ch12_eligibility_traces.td_lambda import TDLambda, TrueOnlineTDLambda
        from src.ch12_eligibility_traces.control_traces import SarsaLambda
        
        n_features = 8
        n_actions = 2
        
        # ç‰¹å¾æå–å™¨
        def features(state):
            f = np.zeros(n_features)
            if isinstance(state, int):
                f[state % n_features] = 1.0
            return f
        
        def sa_features(state, action):
            f = np.zeros(n_features)
            if isinstance(state, int):
                idx = (state * n_actions + action) % n_features
                f[idx] = 1.0
            return f
        
        # åˆ›å»ºæµ‹è¯•å›åˆ
        print("\nåˆ›å»ºæµ‹è¯•å›åˆ...")
        episode = Episode(
            states=[0, 1, 2, 1, 0],
            actions=[0, 1, 0, 1, 0],
            rewards=[-1.0, -1.0, 5.0, -1.0, -1.0]
        )
        
        # è®¡ç®—ä¸åŒÎ»çš„å›æŠ¥
        print("\nä¸åŒÎ»å€¼çš„Î»-return:")
        for lambda_val in [0.0, 0.5, 1.0]:
            calc = LambdaReturn(lambda_=lambda_val, gamma=0.9)
            g = calc.compute_lambda_return(episode, t=0)
            print(f"  Î»={lambda_val}: G^Î»={g:.3f}")
        
        # æ¯”è¾ƒTD(Î»)ç®—æ³•
        print("\nè®­ç»ƒä¸åŒTD(Î»)ç®—æ³•...")
        
        # åŸºç¡€TD(Î»)
        td_lambda = TDLambda(
            n_features=n_features,
            feature_extractor=features,
            lambda_=0.9,
            alpha=0.1,
            gamma=0.9
        )
        
        # çœŸæ­£çš„åœ¨çº¿TD(Î»)
        true_online = TrueOnlineTDLambda(
            n_features=n_features,
            feature_extractor=features,
            lambda_=0.9,
            alpha=0.1,
            gamma=0.9
        )
        
        # è®­ç»ƒ
        for _ in range(2):
            for i in range(len(episode.states) - 1):
                state = episode.states[i]
                reward = episode.rewards[i]
                next_state = episode.states[i + 1]
                done = (i == len(episode.states) - 2)
                
                td_lambda.update(state, reward, next_state, done)
                true_online.update(state, reward, next_state, done)
        
        # æ¯”è¾ƒä»·å€¼ä¼°è®¡
        print("\nä»·å€¼ä¼°è®¡æ¯”è¾ƒ:")
        print("çŠ¶æ€  TD(Î»)   çœŸæ­£åœ¨çº¿")
        print("-" * 25)
        for state in range(3):
            v_td = td_lambda.get_value(state)
            v_online = true_online.get_value(state)
            print(f"{state:3d}  {v_td:7.3f}  {v_online:7.3f}")
        
        # æµ‹è¯•Sarsa(Î»)
        print("\næµ‹è¯•Sarsa(Î»)æ§åˆ¶...")
        sarsa = SarsaLambda(
            n_features=n_features,
            n_actions=n_actions,
            feature_extractor=sa_features,
            lambda_=0.9,
            alpha=0.1,
            gamma=0.9,
            epsilon=0.1
        )
        
        # ç®€å•ç¯å¢ƒ
        class SimpleEnv:
            def __init__(self):
                self.state = 0
            
            def reset(self):
                self.state = 0
                return self.state
            
            def step(self, action):
                if action == 0:
                    self.state = max(0, self.state - 1)
                else:
                    self.state = min(2, self.state + 1)
                
                reward = 5.0 if self.state == 2 else -1.0
                done = self.state == 2
                
                return self.state, reward, done, {}
        
        env = SimpleEnv()
        total_return, steps = sarsa.learn_episode(env, max_steps=20)
        print(f"\nSarsa(Î»)å›åˆ: å›æŠ¥={total_return:.1f}, æ­¥æ•°={steps}")
        
        print("\nâœ… é›†æˆåœºæ™¯æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"\nâŒ é›†æˆåœºæ™¯æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


def main():
    """
    è¿è¡Œæ‰€æœ‰æµ‹è¯•
    Run all tests
    """
    print("\n" + "="*80)
    print("ç¬¬12ç« ï¼šèµ„æ ¼è¿¹ - æ¨¡å—æµ‹è¯•")
    print("Chapter 12: Eligibility Traces - Module Tests")
    print("="*80)
    
    tests = [
        ("Î»-return", test_lambda_return),
        ("TD(Î»)ç®—æ³•", test_td_lambda),
        ("æ§åˆ¶ç®—æ³•èµ„æ ¼è¿¹", test_control_traces),
        ("é›†æˆåœºæ™¯", test_integration)
    ]
    
    results = []
    start_time = time.time()
    
    for name, test_func in tests:
        print(f"\nè¿è¡Œæµ‹è¯•: {name}")
        success = test_func()
        results.append((name, success))
        
        if not success:
            print(f"\nâš ï¸ æµ‹è¯•å¤±è´¥ï¼Œåœæ­¢åç»­æµ‹è¯•")
            break
    
    total_time = time.time() - start_time
    
    # æ€»ç»“
    print("\n" + "="*80)
    print("æµ‹è¯•æ€»ç»“ Test Summary")
    print("="*80)
    
    all_passed = True
    for name, success in results:
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        print(f"{name}: {status}")
        if not success:
            all_passed = False
    
    print(f"\næ€»æµ‹è¯•æ—¶é—´: {total_time:.2f}ç§’")
    
    if all_passed:
        print("\nğŸ‰ ç¬¬12ç« æ‰€æœ‰èµ„æ ¼è¿¹æ¨¡å—æµ‹è¯•é€šè¿‡ï¼")
        print("ğŸ‰ All Chapter 12 Eligibility Traces modules passed!")
        print("\nèµ„æ ¼è¿¹å®ç°éªŒè¯å®Œæˆ:")
        print("âœ“ Î»-returnæ–¹æ³•")
        print("âœ“ TD(Î»)ç®—æ³•")
        print("âœ“ Sarsa(Î»)å’ŒQ(Î»)")
        print("âœ“ çœŸæ­£çš„åœ¨çº¿ç®—æ³•")
        print("\nç»Ÿä¸€äº†TDå’ŒMCçš„ä¼˜é›…æ¡†æ¶ï¼")
        print("Elegant framework unifying TD and MC!")
        print("\nå‡†å¤‡è¿›å…¥ç¬¬13ç« ï¼šç­–ç•¥æ¢¯åº¦æ–¹æ³•")
        print("Ready to proceed to Chapter 13: Policy Gradient Methods")
    else:
        print("\nâš ï¸ æœ‰äº›æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç ")
        print("âš ï¸ Some tests failed, please check the code")
    
    return all_passed


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)