#!/usr/bin/env python
"""
æµ‹è¯•ç¬¬9ç« æ‰€æœ‰å‡½æ•°è¿‘ä¼¼æ¨¡å—
Test all Chapter 9 Function Approximation modules

ç¡®ä¿æ‰€æœ‰ç®—æ³•å®ç°æ­£ç¡®
Ensure all algorithm implementations are correct
"""

import sys
import traceback
import numpy as np
from pathlib import Path
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))


def test_gradient_descent():
    """
    æµ‹è¯•æ¢¯åº¦ä¸‹é™åŸºç¡€
    Test gradient descent foundations
    """
    print("\n" + "="*60)
    print("æµ‹è¯•æ¢¯åº¦ä¸‹é™...")
    print("Testing Gradient Descent...")
    print("="*60)
    
    try:
        from src.ch09_on_policy_approximation.gradient_descent import (
            ValueFunctionApproximator, SimpleLinearApproximator,
            GradientDescent, StochasticGradientDescent, MiniBatchGradientDescent
        )
        
        # åˆ›å»ºç®€å•çš„çº¿æ€§è¿‘ä¼¼å™¨
        print("\næµ‹è¯•å€¼å‡½æ•°è¿‘ä¼¼å™¨...")
        n_features = 10
        
        def poly_features(s):
            return np.array([s**i for i in range(n_features)])
        
        approx = SimpleLinearApproximator(n_features, poly_features)
        print("âœ“ åˆ›å»ºçº¿æ€§è¿‘ä¼¼å™¨")
        
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        n_samples = 50
        x = np.linspace(-1, 1, n_samples)
        y_true = [np.sin(2 * xi) for xi in x]
        
        # æµ‹è¯•æ‰¹é‡æ¢¯åº¦ä¸‹é™
        print("\næµ‹è¯•æ‰¹é‡æ¢¯åº¦ä¸‹é™...")
        bgd = GradientDescent(learning_rate=0.1)
        results = bgd.optimize(approx, x, y_true, n_epochs=20, tolerance=1e-6)
        assert 'losses' in results
        assert len(results['losses']) > 0
        print(f"  âœ“ æ‰¹é‡GDæ”¶æ•›äº{results['n_iterations']}æ¬¡è¿­ä»£")
        
        # æµ‹è¯•SGD
        print("\næµ‹è¯•éšæœºæ¢¯åº¦ä¸‹é™...")
        approx2 = SimpleLinearApproximator(n_features, poly_features)
        sgd = StochasticGradientDescent(learning_rate=0.1, decay_rate=0.99)
        sgd_results = sgd.train(approx2, list(x), y_true, n_epochs=5)
        assert 'losses' in sgd_results
        print(f"  âœ“ SGDå®Œæˆï¼Œæœ€ç»ˆå­¦ä¹ ç‡={sgd_results['final_learning_rate']:.4f}")
        
        # æµ‹è¯•å°æ‰¹é‡æ¢¯åº¦ä¸‹é™
        print("\næµ‹è¯•å°æ‰¹é‡æ¢¯åº¦ä¸‹é™...")
        approx3 = SimpleLinearApproximator(n_features, poly_features)
        mbgd = MiniBatchGradientDescent(learning_rate=0.1, batch_size=10, momentum=0.9)
        mbgd_results = mbgd.train(approx3, list(x), y_true, n_epochs=5)
        assert 'losses' in mbgd_results
        print(f"  âœ“ å°æ‰¹é‡GDå®Œæˆï¼Œè¿­ä»£æ¬¡æ•°={mbgd_results['n_iterations']}")
        
        print("\nâœ… æ¢¯åº¦ä¸‹é™æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"\nâŒ æ¢¯åº¦ä¸‹é™æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


def test_linear_approximation():
    """
    æµ‹è¯•çº¿æ€§å‡½æ•°è¿‘ä¼¼
    Test linear function approximation
    """
    print("\n" + "="*60)
    print("æµ‹è¯•çº¿æ€§å‡½æ•°è¿‘ä¼¼...")
    print("Testing Linear Function Approximation...")
    print("="*60)
    
    try:
        from src.ch09_on_policy_approximation.linear_approximation import (
            LinearFeatures, LinearValueFunction,
            GradientMonteCarlo, SemiGradientTD, SemiGradientTDLambda
        )
        from src.ch03_finite_mdp.gridworld import GridWorld
        from src.ch03_finite_mdp.policies_and_values import UniformRandomPolicy
        
        # åˆ›å»ºç¯å¢ƒ
        env = GridWorld(rows=3, cols=3, start_pos=(0,0), goal_pos=(2,2))
        print("âœ“ åˆ›å»º3Ã—3ç½‘æ ¼ä¸–ç•Œ")
        
        # åˆ›å»ºç‰¹å¾æå–å™¨
        n_features = 9
        feature_extractor = LinearFeatures(n_features)
        print(f"âœ“ åˆ›å»º{n_features}ç»´ç‰¹å¾æå–å™¨")
        
        # æµ‹è¯•ç‰¹å¾æå–
        state = env.state_space[0]
        features = feature_extractor.extract(state)
        assert len(features) == n_features
        print("  âœ“ ç‰¹å¾æå–æµ‹è¯•é€šè¿‡")
        
        # åˆ›å»ºç­–ç•¥
        policy = UniformRandomPolicy(env.action_space)
        
        # æµ‹è¯•çº¿æ€§å€¼å‡½æ•°
        print("\næµ‹è¯•çº¿æ€§å€¼å‡½æ•°...")
        value_func = LinearValueFunction(feature_extractor)
        prediction = value_func.predict(state)
        assert isinstance(prediction, (float, np.floating))
        
        td_error = value_func.update(state, 1.0, 0.01)
        assert isinstance(td_error, (float, np.floating))
        print("  âœ“ çº¿æ€§å€¼å‡½æ•°æµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•æ¢¯åº¦è’™ç‰¹å¡æ´›
        print("\næµ‹è¯•æ¢¯åº¦è’™ç‰¹å¡æ´›...")
        gmc = GradientMonteCarlo(env, feature_extractor, gamma=0.9, alpha=0.01)
        v_gmc = gmc.learn(policy, n_episodes=10, verbose=False)
        assert v_gmc.update_count > 0
        print(f"  âœ“ æ¢¯åº¦MCå®Œæˆï¼Œæ›´æ–°æ¬¡æ•°={v_gmc.update_count}")
        
        # æµ‹è¯•åŠæ¢¯åº¦TD
        print("\næµ‹è¯•åŠæ¢¯åº¦TD(0)...")
        feature_extractor2 = LinearFeatures(n_features)
        sgtd = SemiGradientTD(env, feature_extractor2, gamma=0.9, alpha=0.01)
        v_sgtd = sgtd.learn(policy, n_episodes=10, verbose=False)
        assert sgtd.step_count > 0
        print(f"  âœ“ åŠæ¢¯åº¦TDå®Œæˆï¼Œæ­¥æ•°={sgtd.step_count}")
        
        # æµ‹è¯•åŠæ¢¯åº¦TD(Î»)
        print("\næµ‹è¯•åŠæ¢¯åº¦TD(Î»)...")
        feature_extractor3 = LinearFeatures(n_features)
        sgtd_lambda = SemiGradientTDLambda(
            env, feature_extractor3, gamma=0.9, alpha=0.01, lambda_=0.5
        )
        v_lambda = sgtd_lambda.learn(policy, n_episodes=10, verbose=False)
        assert sgtd_lambda.step_count > 0
        print(f"  âœ“ åŠæ¢¯åº¦TD(Î»)å®Œæˆï¼Œæ­¥æ•°={sgtd_lambda.step_count}")
        
        print("\nâœ… çº¿æ€§å‡½æ•°è¿‘ä¼¼æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"\nâŒ çº¿æ€§å‡½æ•°è¿‘ä¼¼æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


def test_feature_construction():
    """
    æµ‹è¯•ç‰¹å¾æ„é€ æ–¹æ³•
    Test feature construction methods
    """
    print("\n" + "="*60)
    print("æµ‹è¯•ç‰¹å¾æ„é€ ...")
    print("Testing Feature Construction...")
    print("="*60)
    
    try:
        from src.ch09_on_policy_approximation.feature_construction import (
            PolynomialFeatures, FourierBasis, RadialBasisFunction,
            TileCoding, Iht
        )
        
        # æµ‹è¯•çŠ¶æ€ç©ºé—´
        bounds = [(0, 10), (0, 10)]
        test_state = np.array([5.0, 5.0])
        
        # æµ‹è¯•å¤šé¡¹å¼ç‰¹å¾
        print("\næµ‹è¯•å¤šé¡¹å¼ç‰¹å¾...")
        poly = PolynomialFeatures(degree=2, include_bias=True)
        poly_features = poly.transform(test_state)
        # å¦‚æœè¿”å›2Dæ•°ç»„ï¼Œå–ç¬¬ä¸€è¡Œ
        if poly_features.ndim == 2:
            poly_features = poly_features[0]
        # å¤šé¡¹å¼ç‰¹å¾åº”è¯¥åŒ…å«ï¼š1, x1, x2, x1^2, x1*x2, x2^2 = 6ä¸ªç‰¹å¾
        assert len(poly_features) == 6
        print(f"  âœ“ å¤šé¡¹å¼ç‰¹å¾: è¾“å…¥2ç»´ -> è¾“å‡º{len(poly_features)}ç»´")
        
        # æµ‹è¯•å‚…é‡Œå¶åŸº
        print("\næµ‹è¯•å‚…é‡Œå¶åŸº...")
        fourier = FourierBasis(n_features=16, bounds=bounds)
        fourier_features = fourier.transform(test_state)
        assert len(fourier_features) == 16
        assert -1 <= fourier_features.min() <= fourier_features.max() <= 1
        print(f"  âœ“ å‚…é‡Œå¶ç‰¹å¾: 16ç»´ï¼ŒèŒƒå›´[{fourier_features.min():.2f}, {fourier_features.max():.2f}]")
        
        # æµ‹è¯•å¾„å‘åŸºå‡½æ•°
        print("\næµ‹è¯•å¾„å‘åŸºå‡½æ•°...")
        rbf = RadialBasisFunction(n_features=9, bounds=bounds)
        rbf_features = rbf.transform(test_state)
        assert len(rbf_features) == 9
        assert 0 <= rbf_features.min() <= rbf_features.max() <= 1
        active_features = np.sum(rbf_features > 0.1)
        print(f"  âœ“ RBFç‰¹å¾: 9ç»´ï¼Œæ´»è·ƒç‰¹å¾æ•°={active_features}")
        
        # æµ‹è¯•ç“¦ç‰‡ç¼–ç 
        print("\næµ‹è¯•ç“¦ç‰‡ç¼–ç ...")
        tiles = TileCoding(n_tilings=8, bounds=bounds, n_tiles_per_dim=4, iht_size=256)
        active_tiles = tiles.get_tiles(test_state)
        assert len(active_tiles) == 8  # n_tilings
        
        tile_features = tiles.transform(test_state)
        assert len(tile_features) == 256  # iht_size
        assert np.sum(tile_features) == 8  # æ¯ä¸ªç“¦ç‰‡ä¸€ä¸ªæ´»è·ƒç‰¹å¾
        print(f"  âœ“ ç“¦ç‰‡ç¼–ç : {len(tile_features)}ç»´ï¼Œç¨€ç–åº¦={1 - np.sum(tile_features > 0) / len(tile_features):.1%}")
        
        print("\nâœ… ç‰¹å¾æ„é€ æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"\nâŒ ç‰¹å¾æ„é€ æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


def test_least_squares_td():
    """
    æµ‹è¯•æœ€å°äºŒä¹˜TD
    Test Least-Squares TD
    """
    print("\n" + "="*60)
    print("æµ‹è¯•æœ€å°äºŒä¹˜TD...")
    print("Testing Least-Squares TD...")
    print("="*60)
    
    try:
        from src.ch09_on_policy_approximation.least_squares_td import (
            LeastSquaresTD, LeastSquaresTDLambda, RecursiveLeastSquaresTD
        )
        from src.ch09_on_policy_approximation.linear_approximation import LinearFeatures
        from src.ch03_finite_mdp.gridworld import GridWorld
        from src.ch03_finite_mdp.policies_and_values import UniformRandomPolicy
        
        # åˆ›å»ºç¯å¢ƒ
        env = GridWorld(rows=3, cols=3, start_pos=(0,0), goal_pos=(2,2))
        print("âœ“ åˆ›å»º3Ã—3ç½‘æ ¼ä¸–ç•Œ")
        
        # åˆ›å»ºç‰¹å¾æå–å™¨
        n_features = 9
        feature_extractor = LinearFeatures(n_features)
        
        # åˆ›å»ºç­–ç•¥
        policy = UniformRandomPolicy(env.action_space)
        
        # æ”¶é›†æ ·æœ¬
        print("\næ”¶é›†è®­ç»ƒæ ·æœ¬...")
        samples = []
        for _ in range(20):
            state = env.reset()
            while not state.is_terminal:
                action = policy.select_action(state)
                next_state, reward, done, _ = env.step(action)
                samples.append((state, reward, next_state))
                state = next_state
                if done:
                    break
        print(f"  âœ“ æ”¶é›†äº†{len(samples)}ä¸ªæ ·æœ¬")
        
        # æµ‹è¯•LSTD(0)
        print("\næµ‹è¯•LSTD(0)...")
        lstd = LeastSquaresTD(feature_extractor, gamma=0.9, epsilon=0.01)
        for state, reward, next_state in samples:
            lstd.add_sample(state, reward, next_state)
        
        weights = lstd.solve()
        assert len(weights) == n_features
        print(f"  âœ“ LSTD(0)æ±‚è§£å®Œæˆï¼Œæƒé‡èŒƒæ•°={np.linalg.norm(weights):.3f}")
        
        # æµ‹è¯•LSTD(Î»)
        print("\næµ‹è¯•LSTD(Î»)...")
        lstd_lambda = LeastSquaresTDLambda(
            feature_extractor, gamma=0.9, lambda_=0.5, epsilon=0.01
        )
        
        # é‡ç½®èµ„æ ¼è¿¹åœ¨æ–°å›åˆå¼€å§‹
        for i, (state, reward, next_state) in enumerate(samples):
            if i > 0 and samples[i-1][2].is_terminal:
                lstd_lambda.z = np.zeros(n_features)
            lstd_lambda.add_sample(state, reward, next_state)
        
        weights_lambda = lstd_lambda.solve()
        assert len(weights_lambda) == n_features
        print(f"  âœ“ LSTD(Î»)æ±‚è§£å®Œæˆï¼Œæƒé‡èŒƒæ•°={np.linalg.norm(weights_lambda):.3f}")
        
        # æµ‹è¯•é€’å½’LSTD
        print("\næµ‹è¯•é€’å½’LSTD...")
        rlstd = RecursiveLeastSquaresTD(feature_extractor, gamma=0.9, epsilon=0.01)
        
        for i, (state, reward, next_state) in enumerate(samples):
            if i > 0 and samples[i-1][2].is_terminal:
                rlstd.z = np.zeros(n_features)
            rlstd.update(state, reward, next_state)
        
        assert len(rlstd.weights) == n_features
        print(f"  âœ“ é€’å½’LSTDå®Œæˆï¼Œæƒé‡èŒƒæ•°={np.linalg.norm(rlstd.weights):.3f}")
        
        # æ¯”è¾ƒæƒé‡å·®å¼‚
        diff = np.linalg.norm(rlstd.weights - weights)
        print(f"  é€’å½’vsæ‰¹é‡æƒé‡å·®å¼‚: {diff:.4f}")
        
        print("\nâœ… æœ€å°äºŒä¹˜TDæµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"\nâŒ æœ€å°äºŒä¹˜TDæµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


def test_neural_approximation():
    """
    æµ‹è¯•ç¥ç»ç½‘ç»œè¿‘ä¼¼
    Test neural network approximation
    """
    print("\n" + "="*60)
    print("æµ‹è¯•ç¥ç»ç½‘ç»œè¿‘ä¼¼...")
    print("Testing Neural Network Approximation...")
    print("="*60)
    
    try:
        from src.ch09_on_policy_approximation.neural_approximation import (
            NeuralNetwork, ReplayBuffer, Experience,
            DeepQNetwork, GradientTDNN
        )
        
        # æµ‹è¯•åŸºç¡€ç¥ç»ç½‘ç»œ
        print("\næµ‹è¯•ç¥ç»ç½‘ç»œ...")
        nn = NeuralNetwork(input_size=2, hidden_size=4, output_size=1,
                          learning_rate=0.1)
        
        # ç®€å•çš„è®­ç»ƒæ•°æ®
        X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
        y = np.array([[0], [1], [1], [0]])  # XOR
        
        # è®­ç»ƒå‡ æ­¥
        for _ in range(100):
            for i in range(len(X)):
                loss = nn.train_step(X[i], y[i])
        
        # æµ‹è¯•é¢„æµ‹
        prediction = nn.predict(X[0])
        assert isinstance(prediction, (float, np.floating))
        print(f"  âœ“ ç¥ç»ç½‘ç»œæµ‹è¯•é€šè¿‡ï¼Œæ›´æ–°æ¬¡æ•°={nn.update_count}")
        
        # æµ‹è¯•ç»éªŒå›æ”¾ç¼“å†²
        print("\næµ‹è¯•ç»éªŒå›æ”¾ç¼“å†²...")
        buffer = ReplayBuffer(capacity=100)
        
        for i in range(50):
            exp = Experience(
                state=np.random.randn(4),
                action=i % 2,
                reward=np.random.randn(),
                next_state=np.random.randn(4),
                done=i % 10 == 0
            )
            buffer.push(exp)
        
        assert len(buffer) == 50
        batch = buffer.sample(10)
        assert len(batch) == 10
        print(f"  âœ“ å›æ”¾ç¼“å†²æµ‹è¯•é€šè¿‡ï¼Œå¤§å°={len(buffer)}")
        
        # æµ‹è¯•DQN
        print("\næµ‹è¯•DQN...")
        dqn = DeepQNetwork(
            state_size=4,
            action_size=2,
            hidden_size=16,
            learning_rate=0.001,
            buffer_size=100,
            batch_size=8,
            target_update_freq=10
        )
        
        # æ·»åŠ ç»éªŒ
        for _ in range(20):
            state = np.random.randn(4)
            action = dqn.select_action(state, epsilon=0.5)
            reward = np.random.randn()
            next_state = np.random.randn(4)
            done = np.random.random() > 0.8
            
            dqn.store_experience(state, action, reward, next_state, done)
        
        # è®­ç»ƒ
        loss = dqn.train_batch()
        assert dqn.update_count > 0
        print(f"  âœ“ DQNæµ‹è¯•é€šè¿‡ï¼Œæ›´æ–°æ¬¡æ•°={dqn.update_count}")
        
        # æµ‹è¯•æ¢¯åº¦TDç¥ç»ç½‘ç»œ
        print("\næµ‹è¯•æ¢¯åº¦TDç¥ç»ç½‘ç»œ...")
        gtd_nn = GradientTDNN(state_size=4, hidden_size=16,
                             learning_rate=0.001, gamma=0.9)
        
        for _ in range(10):
            state = np.random.randn(4)
            reward = np.random.randn()
            next_state = np.random.randn(4)
            done = np.random.random() > 0.8
            
            td_error = gtd_nn.update(state, reward, next_state, done)
            assert isinstance(td_error, (float, np.floating))
        
        assert gtd_nn.update_count > 0
        print(f"  âœ“ æ¢¯åº¦TDç¥ç»ç½‘ç»œæµ‹è¯•é€šè¿‡ï¼Œæ›´æ–°æ¬¡æ•°={gtd_nn.update_count}")
        
        print("\nâœ… ç¥ç»ç½‘ç»œè¿‘ä¼¼æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"\nâŒ ç¥ç»ç½‘ç»œè¿‘ä¼¼æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


def main():
    """
    è¿è¡Œæ‰€æœ‰æµ‹è¯•
    Run all tests
    """
    print("\n" + "="*80)
    print("ç¬¬9ç« ï¼šåŒç­–ç•¥é¢„æµ‹ä¸è¿‘ä¼¼ - æ¨¡å—æµ‹è¯•")
    print("Chapter 9: On-policy Prediction with Approximation - Module Tests")
    print("="*80)
    
    tests = [
        ("æ¢¯åº¦ä¸‹é™", test_gradient_descent),
        ("çº¿æ€§å‡½æ•°è¿‘ä¼¼", test_linear_approximation),
        ("ç‰¹å¾æ„é€ ", test_feature_construction),
        ("æœ€å°äºŒä¹˜TD", test_least_squares_td),
        ("ç¥ç»ç½‘ç»œè¿‘ä¼¼", test_neural_approximation)
    ]
    
    results = []
    start_time = time.time()
    
    for name, test_func in tests:
        print(f"\nè¿è¡Œæµ‹è¯•: {name}")
        success = test_func()
        results.append((name, success))
        
        if not success:
            print(f"\nâš ï¸ æµ‹è¯•å¤±è´¥ï¼Œåœæ­¢åç»­æµ‹è¯•")
            break
    
    total_time = time.time() - start_time
    
    # æ€»ç»“
    print("\n" + "="*80)
    print("æµ‹è¯•æ€»ç»“ Test Summary")
    print("="*80)
    
    all_passed = True
    for name, success in results:
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        print(f"{name}: {status}")
        if not success:
            all_passed = False
    
    print(f"\næ€»æµ‹è¯•æ—¶é—´: {total_time:.2f}ç§’")
    
    if all_passed:
        print("\nğŸ‰ ç¬¬9ç« æ‰€æœ‰å‡½æ•°è¿‘ä¼¼æ¨¡å—æµ‹è¯•é€šè¿‡ï¼")
        print("ğŸ‰ All Chapter 9 Function Approximation modules passed!")
        print("\nå‡½æ•°è¿‘ä¼¼å®ç°éªŒè¯å®Œæˆ:")
        print("âœ“ æ¢¯åº¦ä¸‹é™åŸºç¡€")
        print("âœ“ çº¿æ€§å‡½æ•°è¿‘ä¼¼")
        print("âœ“ ç‰¹å¾æ„é€ æ–¹æ³•")
        print("âœ“ æœ€å°äºŒä¹˜TD")
        print("âœ“ ç¥ç»ç½‘ç»œè¿‘ä¼¼")
        print("\nä»è¡¨æ ¼åˆ°å‡½æ•°è¿‘ä¼¼çš„é£è·ƒï¼")
        print("The leap from tabular to function approximation!")
        print("\nå¯ä»¥ç»§ç»­å­¦ä¹ ç¬¬10ç« æˆ–å¼€å§‹å®é™…é¡¹ç›®")
        print("Ready to proceed to Chapter 10 or start practical projects")
    else:
        print("\nâš ï¸ æœ‰äº›æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç ")
        print("âš ï¸ Some tests failed, please check the code")
    
    return all_passed


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)