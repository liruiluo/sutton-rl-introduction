#!/usr/bin/env python
"""
æµ‹è¯•ç¬¬2ç« æ‰€æœ‰æ¨¡å—
Test all Chapter 2 modules

ç¡®ä¿æ‰€æœ‰å®ç°æ­£ç¡®å·¥ä½œ
Ensure all implementations work correctly
"""

import sys
import traceback
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))


def test_mdp_framework():
    """æµ‹è¯•MDPæ¡†æ¶"""
    print("\n" + "="*60)
    print("æµ‹è¯•MDPæ¡†æ¶...")
    print("Testing MDP Framework...")
    print("="*60)
    
    try:
        from src.ch03_finite_mdp.mdp_framework import (
            State, Action, MDPEnvironment, MDPAgent,
            RecyclingRobot, MDPMathematics
        )
        
        # åˆ›å»ºç¯å¢ƒ
        env = RecyclingRobot()
        print(f"âœ“ åˆ›å»ºå›æ”¶æœºå™¨äººç¯å¢ƒ: {env.name}")
        
        # é‡ç½®ç¯å¢ƒ
        state = env.reset()
        print(f"âœ“ é‡ç½®åˆ°åˆå§‹çŠ¶æ€: {state.id}")
        
        # æ‰§è¡ŒåŠ¨ä½œ
        from src.ch03_finite_mdp.mdp_framework import Action
        search_action = Action(id='search', name='æœç´¢åƒåœ¾')
        next_state, reward, done, info = env.step(search_action)
        print(f"âœ“ æ‰§è¡ŒåŠ¨ä½œ: {search_action.name} -> å¥–åŠ±={reward}")
        
        print("\nâœ… MDPæ¡†æ¶æµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"\nâŒ MDPæ¡†æ¶æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


def test_agent_environment_interface():
    """æµ‹è¯•æ™ºèƒ½ä½“-ç¯å¢ƒæ¥å£"""
    print("\n" + "="*60)
    print("æµ‹è¯•æ™ºèƒ½ä½“-ç¯å¢ƒæ¥å£...")
    print("Testing Agent-Environment Interface...")
    print("="*60)
    
    try:
        from src.ch03_finite_mdp.agent_environment_interface import (
            Experience, Trajectory, Episode,
            AgentEnvironmentInterface, RandomAgent,
            ExperienceBuffer
        )
        from src.ch03_finite_mdp.mdp_framework import RecyclingRobot, Action
        
        # åˆ›å»ºç¯å¢ƒ
        env = RecyclingRobot()
        
        # åˆ›å»ºå—é™çš„åŠ¨ä½œç©ºé—´ï¼ˆé«˜ç”µé‡æ—¶ä¸èƒ½å……ç”µï¼‰
        # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨å‰ä¸¤ä¸ªåŠ¨ä½œï¼ˆsearchå’Œwaitï¼‰ï¼Œé¿å…recharge
        limited_actions = [
            Action(id='search', name='æœç´¢åƒåœ¾'),
            Action(id='wait', name='ç­‰å¾…')
        ]
        agent = RandomAgent(limited_actions)
        print(f"âœ“ åˆ›å»ºéšæœºæ™ºèƒ½ä½“: {agent.name}")
        
        # åˆ›å»ºæ¥å£
        interface = AgentEnvironmentInterface(agent, env)
        print(f"âœ“ åˆ›å»ºæ™ºèƒ½ä½“-ç¯å¢ƒæ¥å£")
        
        # è¿è¡Œä¸€ä¸ªå›åˆ
        episode = interface.run_episode(max_steps=10)
        print(f"âœ“ è¿è¡Œå›åˆ: æ­¥æ•°={len(episode.trajectory)}, "
              f"å¥–åŠ±={episode.return_value:.2f}")
        
        # æµ‹è¯•ç»éªŒç¼“å†²åŒº
        buffer = ExperienceBuffer(capacity=100)
        buffer.add_trajectory(episode.trajectory)
        print(f"âœ“ ç»éªŒç¼“å†²åŒº: å¤§å°={len(buffer)}")
        
        print("\nâœ… æ™ºèƒ½ä½“-ç¯å¢ƒæ¥å£æµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"\nâŒ æ™ºèƒ½ä½“-ç¯å¢ƒæ¥å£æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


def test_policies_and_values():
    """æµ‹è¯•ç­–ç•¥å’Œä»·å€¼å‡½æ•°"""
    print("\n" + "="*60)
    print("æµ‹è¯•ç­–ç•¥å’Œä»·å€¼å‡½æ•°...")
    print("Testing Policies and Value Functions...")
    print("="*60)
    
    try:
        from src.ch03_finite_mdp.policies_and_values import (
            Policy, DeterministicPolicy, StochasticPolicy,
            UniformRandomPolicy, StateValueFunction,
            ActionValueFunction, BellmanEquations,
            PolicyEvaluation
        )
        from src.ch03_finite_mdp.mdp_framework import RecyclingRobot
        
        # åˆ›å»ºç¯å¢ƒ
        env = RecyclingRobot()
        
        # åˆ›å»ºéšæœºç­–ç•¥
        random_policy = UniformRandomPolicy(env.action_space)
        print(f"âœ“ åˆ›å»ºéšæœºç­–ç•¥")
        
        # è·å–åŠ¨ä½œæ¦‚ç‡
        state = env.state_space[0]
        probs = random_policy.get_action_probabilities(state)
        print(f"âœ“ è·å–åŠ¨ä½œæ¦‚ç‡: {len(probs)}ä¸ªåŠ¨ä½œ")
        
        # åˆ›å»ºä»·å€¼å‡½æ•°
        V = StateValueFunction(env.state_space, initial_value=0.0)
        print(f"âœ“ åˆ›å»ºçŠ¶æ€ä»·å€¼å‡½æ•°: {len(env.state_space)}ä¸ªçŠ¶æ€")
        
        Q = ActionValueFunction(env.state_space, env.action_space, initial_value=0.0)
        print(f"âœ“ åˆ›å»ºåŠ¨ä½œä»·å€¼å‡½æ•°")
        
        # ç­–ç•¥è¯„ä¼°ï¼ˆç®€å•æµ‹è¯•ï¼‰
        print("âœ“ æµ‹è¯•ç­–ç•¥è¯„ä¼°...")
        V_evaluated = PolicyEvaluation.evaluate_policy(
            random_policy, env, gamma=0.9, theta=0.01, max_iterations=10
        )
        print(f"  è¯„ä¼°åV(high)={V_evaluated.get_value(env.state_space[0]):.3f}")
        
        print("\nâœ… ç­–ç•¥å’Œä»·å€¼å‡½æ•°æµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"\nâŒ ç­–ç•¥å’Œä»·å€¼å‡½æ•°æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


def test_gridworld():
    """æµ‹è¯•ç½‘æ ¼ä¸–ç•Œ"""
    print("\n" + "="*60)
    print("æµ‹è¯•ç½‘æ ¼ä¸–ç•Œ...")
    print("Testing Grid World...")
    print("="*60)
    
    try:
        from src.ch03_finite_mdp.gridworld import (
            GridWorld, GridWorldAgent, GridWorldVisualizer
        )
        
        # åˆ›å»ºç½‘æ ¼ä¸–ç•Œ
        env = GridWorld(rows=3, cols=3, start_pos=(0, 0), goal_pos=(2, 2))
        print(f"âœ“ åˆ›å»º3Ã—3ç½‘æ ¼ä¸–ç•Œ")
        
        # é‡ç½®ç¯å¢ƒ
        state = env.reset()
        print(f"âœ“ é‡ç½®åˆ°èµ·å§‹ä½ç½®: {env.current_pos}")
        
        # åˆ›å»ºæ™ºèƒ½ä½“
        agent = GridWorldAgent(env, learning_algorithm="q_learning")
        print(f"âœ“ åˆ›å»ºQå­¦ä¹ æ™ºèƒ½ä½“")
        
        # æ‰§è¡Œå‡ æ­¥
        for i in range(3):
            action = agent.select_action(state)
            next_state, reward, done, info = env.step(action)
            agent.update(state, action, reward, next_state, done)
            state = next_state
            print(f"  æ­¥éª¤{i+1}: {action.name} -> ä½ç½®{info['position']}")
            if done:
                print(f"âœ“ åˆ°è¾¾ç›®æ ‡ï¼")
                break
        
        # æ¸²æŸ“ï¼ˆæ–‡æœ¬æ¨¡å¼ï¼‰
        print("\nç½‘æ ¼ä¸–ç•ŒçŠ¶æ€:")
        env.render(mode='human')
        
        print("\nâœ… ç½‘æ ¼ä¸–ç•Œæµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"\nâŒ ç½‘æ ¼ä¸–ç•Œæµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "="*80)
    print("ç¬¬2ç« ï¼šæœ‰é™é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ - æ¨¡å—æµ‹è¯•")
    print("Chapter 2: Finite MDPs - Module Tests")
    print("="*80)
    
    tests = [
        ("MDPæ¡†æ¶", test_mdp_framework),
        ("æ™ºèƒ½ä½“-ç¯å¢ƒæ¥å£", test_agent_environment_interface),
        ("ç­–ç•¥å’Œä»·å€¼å‡½æ•°", test_policies_and_values),
        ("ç½‘æ ¼ä¸–ç•Œ", test_gridworld)
    ]
    
    results = []
    for name, test_func in tests:
        success = test_func()
        results.append((name, success))
    
    # æ€»ç»“
    print("\n" + "="*80)
    print("æµ‹è¯•æ€»ç»“ Test Summary")
    print("="*80)
    
    all_passed = True
    for name, success in results:
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        print(f"{name}: {status}")
        if not success:
            all_passed = False
    
    if all_passed:
        print("\nğŸ‰ ç¬¬2ç« æ‰€æœ‰æ¨¡å—æµ‹è¯•é€šè¿‡ï¼")
        print("ğŸ‰ All Chapter 2 modules passed!")
        print("\nå¯ä»¥ç»§ç»­å­¦ä¹ ç¬¬3ç« ï¼šåŠ¨æ€è§„åˆ’")
        print("Ready to proceed to Chapter 3: Dynamic Programming")
    else:
        print("\nâš ï¸ æœ‰äº›æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç ")
        print("âš ï¸ Some tests failed, please check the code")
    
    return all_passed


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)